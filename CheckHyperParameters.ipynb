{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca7e361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T19:50:39.883658Z",
     "start_time": "2022-09-06T19:50:39.879832Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5baba3e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T19:50:43.277299Z",
     "start_time": "2022-09-06T19:50:39.886318Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n",
      "/root/.cache/torch/hub/pytorch_vision_main/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n",
      "/root/.cache/torch/hub/pytorch_vision_main/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n",
      "/root/.cache/torch/hub/pytorch_vision_main/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load(\"pytorch/vision\", \"vit_b_16\")\n",
    "\n",
    "import torchvision\n",
    "from Models.transformer import VisionTransformer as vit\n",
    "import Models.Conv as conv\n",
    "\n",
    "from DataLoader import CIFAR100\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import utils\n",
    "\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455232d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T19:50:44.957692Z",
     "start_time": "2022-09-06T19:50:43.279752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = CIFAR100.get_data(58*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f354bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T19:51:05.393740Z",
     "start_time": "2022-09-06T19:50:44.959976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher = vit(class_num = 100, pretrained = True)\n",
    "teacher.load_state_dict(torch.load(\"saved_models/vit_b_16_m_0_9_std_0_4_acc_89_01.pth\").module.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62985e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T19:51:05.456410Z",
     "start_time": "2022-09-06T19:51:05.396043Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "teacher = teacher.to(device)\n",
    "teacher = torch.nn.DataParallel(teacher, device_ids=[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "937b7eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T19:51:05.463452Z",
     "start_time": "2022-09-06T19:51:05.458425Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion_onlylabel = lambda a,b : mse(a*b, b)\n",
    "criterion_CE = nn.CrossEntropyLoss()\n",
    "mse = nn.MSELoss()\n",
    "softmax = torch.nn.Softmax(dim = 1)\n",
    "criterion_KLD = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "criterion_response = lambda a,b : criterion_KLD(torch.log_softmax(a, dim=1),torch.softmax(b, dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a3d713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T19:51:05.476647Z",
     "start_time": "2022-09-06T19:51:05.465235Z"
    }
   },
   "outputs": [],
   "source": [
    "T_optimizer = optim.SGD(teacher.parameters(), lr=0.01, momentum=0.9)\n",
    "CE_loss = nn.CrossEntropyLoss()\n",
    "T_scheduler = torch.optim.lr_scheduler.MultiStepLR(T_optimizer, milestones=[1,2,3,4,5,6,7], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d868ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T19:12:52.538326Z",
     "start_time": "2022-09-06T19:12:52.524748Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e8b2a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-06T19:50:40.353Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/288 [00:19<1:33:54, 19.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9712643623352051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 11/288 [00:26<04:00,  1.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9801462888717651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/288 [00:33<03:08,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9797482490539551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 31/288 [00:39<02:59,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9766407608985901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 41/288 [00:46<02:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.97715163230896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 51/288 [00:53<02:41,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9758845567703247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 61/288 [00:59<02:35,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9757866859436035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 71/288 [01:06<02:29,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9757972955703735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 81/288 [01:12<02:21,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9748119711875916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 91/288 [01:19<02:14,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.97517991065979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 101/288 [01:25<02:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9747353792190552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 111/288 [01:31<02:01,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9739567041397095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 121/288 [01:38<01:54,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9734492301940918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 131/288 [01:45<01:47,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9738527536392212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 141/288 [01:51<01:40,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.9734246134757996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 151/288 [01:58<01:34,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher acc: 0.973700225353241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 156/288 [02:01<01:25,  1.54it/s]"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)\n",
    "best_acc = 0.0\n",
    "stack = 0\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "try:\n",
    "    encoder_length = len(teacher.encoder.layers)\n",
    "except:\n",
    "    encoder_length = len(teacher.module.encoder.layers)\n",
    "\n",
    "\n",
    "T_correct = 0\n",
    "all_data = 0\n",
    "\n",
    "for i, (img, label) in enumerate(tqdm(train_loader)):\n",
    "    teacher.train()\n",
    "    input_data = img.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "\n",
    "    all_data += len(input_data)\n",
    "    input_lrp = utils.get_LRP_img(input_data, label, teacher, criterion_CE, T_optimizer, mean=1.5, std = 0.1, mult = 0.4).cuda()\n",
    "\n",
    "    T_optimizer.zero_grad()\n",
    "\n",
    "    layer = random.randint(0,  2+encoder_length)\n",
    "\n",
    "    output_T, fk_lrp = teacher(input_lrp,layer)\n",
    "\n",
    "\n",
    "    T_correct += sum(label == torch.argmax(output_T, dim=1))\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f\"Teacher acc: {T_correct / all_data}\")\n",
    "        \n",
    "    \n",
    "# print(\"distill loss : \", sum(loss_distill) / len(loss_distill))\n",
    "# print(\"general loss : \", sum(loss_CE) / len(loss_CE))\n",
    "# print(\"response loss : \", sum(loss_response) / len(loss_response))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fea2c5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-06T19:50:40.353Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Teacher acc: {T_correct / all_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff6c602",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-06T19:50:40.354Z"
    }
   },
   "outputs": [],
   "source": [
    "input_lrp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf5837",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-06T19:50:40.354Z"
    }
   },
   "outputs": [],
   "source": [
    "input_lrp.std(dim=(2,3)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit-pytorch",
   "language": "python",
   "name": "vit-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
