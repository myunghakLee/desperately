{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fce4982",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:40:46.403103Z",
     "start_time": "2022-09-16T19:40:46.395084Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31fb0a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:40:49.962955Z",
     "start_time": "2022-09-16T19:40:46.665408Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n",
      "/root/.cache/torch/hub/pytorch_vision_main/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n",
      "/root/.cache/torch/hub/pytorch_vision_main/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load(\"pytorch/vision\", \"vit_b_16\")\n",
    "\n",
    "import torchvision\n",
    "from Models.transformer import VisionTransformer as vit\n",
    "import Models.Conv as conv\n",
    "\n",
    "from DataLoader import CIFAR100\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import utils\n",
    "\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb6e0ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:40:51.806208Z",
     "start_time": "2022-09-16T19:40:49.965173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# train_loader, test_loader = CIFAR100.get_data(58*3)\n",
    "train_loader, test_loader = CIFAR100.get_data(128*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02763ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:41:01.268116Z",
     "start_time": "2022-09-16T19:40:51.808898Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_main\n"
     ]
    }
   ],
   "source": [
    "from Models import Conv\n",
    "\n",
    "depth = 18\n",
    "\n",
    "model = torch.load(f\"saved_models/resnet/resnet{depth}.pth\").module\n",
    "teacher = Conv.resnet_feature(100, depth, model)\n",
    "student = Conv.resnet_feature(100, depth, pretrained=\"IMAGENET1K_V1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35f1909d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:41:01.288976Z",
     "start_time": "2022-09-16T19:41:01.271385Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "teacher = teacher.to(device)\n",
    "teacher = torch.nn.DataParallel(teacher, device_ids=[0, 1])\n",
    "\n",
    "student = student.to(device)\n",
    "student = torch.nn.DataParallel(student, device_ids=[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea623b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:41:01.295245Z",
     "start_time": "2022-09-16T19:41:01.290921Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion_onlylabel = lambda a,b : mse(a*b, b)\n",
    "criterion_CE = nn.CrossEntropyLoss()\n",
    "mse = nn.MSELoss()\n",
    "softmax = torch.nn.Softmax(dim = 1)\n",
    "criterion_KLD = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "criterion_response = lambda a,b : criterion_KLD(torch.log_softmax(a, dim=1),torch.softmax(b, dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a88d7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:41:01.314088Z",
     "start_time": "2022-09-16T19:41:01.296745Z"
    }
   },
   "outputs": [],
   "source": [
    "S_optimizer = optim.SGD(student.parameters(), lr=0.05, momentum=0.9)\n",
    "T_optimizer = optim.SGD(teacher.parameters(), lr=0.05, momentum=0.9)\n",
    "CE_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188a3b9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:41:01.332754Z",
     "start_time": "2022-09-16T19:41:01.316487Z"
    }
   },
   "outputs": [],
   "source": [
    "S_scheduler = torch.optim.lr_scheduler.MultiStepLR(S_optimizer, milestones=[1,2,3,4,5,6,7], gamma=0.1)\n",
    "T_scheduler = torch.optim.lr_scheduler.MultiStepLR(T_optimizer, milestones=[1,2,3,4,5,6,7], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f13fe1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:41:01.350403Z",
     "start_time": "2022-09-16T19:41:01.335831Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.set_seed()\n",
    "\n",
    "best_acc = 0.0\n",
    "stack = 0\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d665fad2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:41:20.737453Z",
     "start_time": "2022-09-16T19:41:01.352980Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:13<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t test acc : 0.7930999994277954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t test acc : 0.011699999682605267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0117, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.test(teacher, test_loader,device)\n",
    "utils.test(student, test_loader,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0470b567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T17:50:21.234369Z",
     "start_time": "2022-09-16T17:50:21.224971Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. channel wise pooling 81.99(dim=1) 82.48(ongoing)(dim=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f478e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-16T19:40:53.246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr : [0.05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 111/131 [01:16<00:13,  1.51it/s]"
     ]
    }
   ],
   "source": [
    "student_test_accs = []\n",
    "layer_num = 4\n",
    "\n",
    "for epoch in range(100):\n",
    "    \n",
    "    print(f\"lr : {S_scheduler.get_last_lr()}\")\n",
    "    if S_scheduler.get_last_lr()[0] < 0.000001:\n",
    "        break\n",
    "        \n",
    "    T_correct = 0\n",
    "    S_correct = 0\n",
    "    all_data = 0\n",
    "    \n",
    "    loss_distill = []\n",
    "    loss_CE = []\n",
    "    loss_response = []\n",
    "    student.train()\n",
    "    teacher.eval()\n",
    "    for img, label in tqdm(train_loader):\n",
    "        input_data = img.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        \n",
    "        all_data += len(input_data)\n",
    "        input_lrp = utils.get_LRP_img(input_data, label, teacher, criterion_CE, T_optimizer, mean=1.5, std = 0.1, mult = 0.4).cuda()\n",
    "        \n",
    "        S_optimizer.zero_grad()\n",
    "        T_optimizer.zero_grad()\n",
    "\n",
    "        layer = random.randint(0,  layer_num)\n",
    "        output_s, fk = student(input_data,layer)\n",
    "        output_t, fk_lrp = teacher(input_lrp,layer)\n",
    "        \n",
    "#         channal wise pooling\n",
    "        fk = torch.mean(fk, dim=2)\n",
    "        fk_lrp = torch.mean(fk_lrp, dim=2)\n",
    "        \n",
    "        distill_loss = mse(fk, fk_lrp)\n",
    "                    \n",
    "        CE_loss = criterion_CE(output_s, label)\n",
    "        \n",
    "        response_loss = criterion_response(output_t, output_s)\n",
    "        \n",
    "        T_correct += sum(label == torch.argmax(output_t, dim=1))\n",
    "        S_correct += sum(label == torch.argmax(output_s, dim=1))\n",
    "        \n",
    "        loss_CE.append(CE_loss.item())\n",
    "        loss_distill.append(distill_loss.item())\n",
    "        loss_response.append(response_loss.item())\n",
    "        \n",
    "        loss = (distill_loss * 3 + CE_loss + response_loss) / 5 # 82.03\n",
    "        loss.backward()\n",
    "        S_optimizer.step()\n",
    "\n",
    "    print(\"distill loss : \", sum(loss_distill) / len(loss_distill))\n",
    "    print(\"general loss : \", sum(loss_CE) / len(loss_CE))\n",
    "    print(\"response loss : \", sum(loss_response) / len(loss_response))\n",
    "    \n",
    "    print(f\"Teacher acc: {T_correct / all_data}\")\n",
    "    print(f\"Student acc: {S_correct / all_data}\")\n",
    "\n",
    "    test_acc = utils.test(student, test_loader,device, epoch) # student도 변하는거 확인 완료함\n",
    "    \n",
    "    if test_acc > best_acc + 0.01:\n",
    "        stack = 0\n",
    "        best_acc = test_acc\n",
    "        \n",
    "    else:\n",
    "        stack+=1\n",
    "    \n",
    "    if stack > 3:  \n",
    "        S_scheduler.step()\n",
    "        stack = 0\n",
    "        \n",
    "    student_test_accs.append(test_acc.item())\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeef3c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T05:02:13.866944Z",
     "start_time": "2022-09-14T05:02:13.866931Z"
    }
   },
   "outputs": [],
   "source": [
    "# distill loss를 2배 키워보는것도 좋을지도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbb7a762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T19:40:15.962529Z",
     "start_time": "2022-09-16T19:40:03.376123Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 \t test acc : 0.7930999994277954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 \t test acc : 0.8247999548912048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8248, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.test(teacher, test_loader,device, epoch) # student도 변하는거 확인 완료함\n",
    "utils.test(student, test_loader,device, epoch) # student도 변하는거 확인 완료함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08941597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T14:25:54.018947Z",
     "start_time": "2022-09-16T14:25:53.810438Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(student, \"saved_models/resnet/resnet{depth}_student.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "623bc543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T14:25:54.066024Z",
     "start_time": "2022-09-16T14:25:54.059241Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"saved_models/resnet/resnet{depth}.json\", \"w\") as f:\n",
    "    json.dump({\"student_test_accs\" : student_test_accs}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e1e4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T05:02:13.871438Z",
     "start_time": "2022-09-14T05:02:13.871425Z"
    }
   },
   "outputs": [],
   "source": [
    "# from Models import Conv\n",
    "\n",
    "# depth = 101\n",
    "\n",
    "# model = torch.load(f\"saved_models/vgg/vgg{depth}.pth\").module\n",
    "# teacher = Conv.resnet_feature(100, depth, model)\n",
    "# student = Conv.resnet_feature(100, depth, pretrained=\"IMAGENET1K_V1\")\n",
    "\n",
    "\n",
    "# device = \"cuda\"\n",
    "\n",
    "# teacher = teacher.to(device)\n",
    "# teacher = torch.nn.DataParallel(teacher, device_ids=[0, 1])\n",
    "\n",
    "# student = student.to(device)\n",
    "# student = torch.nn.DataParallel(student, device_ids=[0, 1])\n",
    "\n",
    "# criterion_onlylabel = lambda a,b : mse(a*b, b)\n",
    "# criterion_CE = nn.CrossEntropyLoss()\n",
    "# mse = nn.MSELoss()\n",
    "# softmax = torch.nn.Softmax(dim = 1)\n",
    "# criterion_KLD = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "# criterion_response = lambda a,b : criterion_KLD(torch.log_softmax(a, dim=1),torch.softmax(b, dim=1))\n",
    "\n",
    "# S_optimizer = optim.SGD(student.parameters(), lr=0.05, momentum=0.9)\n",
    "# T_optimizer = optim.SGD(teacher.parameters(), lr=0.05, momentum=0.9)\n",
    "# CE_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# S_scheduler = torch.optim.lr_scheduler.MultiStepLR(S_optimizer, milestones=[1,2,3,4,5,6,7], gamma=0.1)\n",
    "# T_scheduler = torch.optim.lr_scheduler.MultiStepLR(T_optimizer, milestones=[1,2,3,4,5,6,7], gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# torch.cuda.manual_seed(0)\n",
    "# torch.cuda.manual_seed_all(0)\n",
    "# np.random.seed(0)\n",
    "# cudnn.benchmark = False\n",
    "# cudnn.deterministic = True\n",
    "# random.seed(0)\n",
    "# best_acc = 0.0\n",
    "# stack = 0\n",
    "\n",
    "# accs_train = []\n",
    "# accs_test = []\n",
    "\n",
    "# utils.test(teacher, test_loader,device)\n",
    "# utils.test(student, test_loader,device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit-pytorch",
   "language": "python",
   "name": "vit-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
